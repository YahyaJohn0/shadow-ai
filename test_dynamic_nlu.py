# test_dynamic_nlu.py
import asyncio
import re
import sys
import os
import json

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from shadow_core.dynamic_nlu import SmartNLU, AdvancedInterpreter

class RealisticMockBrain:
    """
    Mock brain that provides realistic AI responses based on query content
    """
    
    async def ask(self, messages):
        user_query = messages[-1]["content"] if messages else ""
        
        # Extract the actual user query from the prompt
        query_match = re.search(r'QUERY:\s*"([^"]+)"', user_query)
        if not query_match:
            return self._get_fallback_response()
        
        actual_query = query_match.group(1).lower()
        
        # Generate realistic responses based on query content
        if any(word in actual_query for word in ['john', 'sarah', 'tell', 'message', 'notify']):
            return self._get_messaging_response(actual_query)
        elif any(word in actual_query for word in ['weather', 'temperature', 'outside']):
            return self._get_weather_response(actual_query)
        elif any(word in actual_query for word in ['remind', 'alarm', 'remember', 'wake up']):
            return self._get_scheduling_response(actual_query)
        elif any(word in actual_query for word in ['open', 'show', 'documents', 'folder']):
            return self._get_automation_response(actual_query)
        elif any(word in actual_query for word in ['shutdown', 'sleep', 'bed', 'quiet']):
            return self._get_system_response(actual_query)
        elif any(word in actual_query for word in ['stock', 'tesla', 'price']):
            return self._get_knowledge_response(actual_query)
        elif any(word in actual_query for word in ['file', 'find', 'search', 'document']):
            return self._get_file_ops_response(actual_query)
        else:
            return self._get_chat_response(actual_query)
    
    def _get_messaging_response(self, query: str):
        contact = "John" if "john" in query else "Sarah" if "sarah" in query else "contact"
        return json.dumps({
            "intent_type": "messaging",
            "confidence": 0.94,
            "action": "send_message",
            "target": contact,
            "parameters": {"message": self._extract_message_content(query), "platform": "whatsapp"},
            "reasoning": f"User wants to send a message to {contact}",
            "urgency": "normal",
            "specificity": "specific"
        })
    
    def _get_weather_response(self, query: str):
        location = "Tokyo" if "tokyo" in query else "London" if "london" in query else "Paris" if "paris" in query else "current location"
        return json.dumps({
            "intent_type": "knowledge",
            "confidence": 0.97,
            "action": "get_weather",
            "target": location,
            "parameters": {"location": location, "timeframe": "current"},
            "reasoning": f"User is asking about weather conditions in {location}",
            "urgency": "normal",
            "specificity": "specific"
        })
    
    def _get_scheduling_response(self, query: str):
        if "alarm" in query or "wake up" in query:
            return json.dumps({
                "intent_type": "scheduling",
                "confidence": 0.95,
                "action": "set_alarm",
                "target": "wake up",
                "parameters": {"time": "07:00", "date": "tomorrow"},
                "reasoning": "User wants to set a wake-up alarm",
                "urgency": "normal",
                "specificity": "specific"
            })
        else:
            return json.dumps({
                "intent_type": "scheduling",
                "confidence": 0.93,
                "action": "set_reminder",
                "target": "meeting",
                "parameters": {"time": "14:00", "message": "Team meeting"},
                "reasoning": "User wants to set a reminder for an event",
                "urgency": "normal",
                "specificity": "specific"
            })
    
    def _get_automation_response(self, query: str):
        if "documents" in query:
            return json.dumps({
                "intent_type": "automation",
                "confidence": 0.91,
                "action": "list_files",
                "target": "documents folder",
                "parameters": {"folder": "documents"},
                "reasoning": "User wants to view contents of documents directory",
                "urgency": "casual",
                "specificity": "specific"
            })
        else:
            return json.dumps({
                "intent_type": "automation",
                "confidence": 0.89,
                "action": "open_app",
                "target": "application",
                "parameters": {"app": "requested_app"},
                "reasoning": "User wants to open an application",
                "urgency": "normal",
                "specificity": "vague"
            })
    
    def _get_system_response(self, query: str):
        return json.dumps({
            "intent_type": "system",
            "confidence": 0.88,
            "action": "sleep_system",
            "target": "computer",
            "parameters": {},
            "reasoning": "User wants to put system to sleep",
            "urgency": "casual",
            "specificity": "vague"
        })
    
    def _get_knowledge_response(self, query: str):
        return json.dumps({
            "intent_type": "knowledge",
            "confidence": 0.96,
            "action": "get_stock",
            "target": "TSLA",
            "parameters": {"symbol": "TSLA"},
            "reasoning": "User wants stock information for Tesla",
            "urgency": "normal",
            "specificity": "specific"
        })
    
    def _get_file_ops_response(self, query: str):
        return json.dumps({
            "intent_type": "file_operations",
            "confidence": 0.90,
            "action": "search_files",
            "target": "recent file",
            "parameters": {"search_term": "recent work", "timeframe": "recent"},
            "reasoning": "User wants to find a recently accessed file",
            "urgency": "normal",
            "specificity": "vague"
        })
    
    def _get_chat_response(self, query: str):
        return json.dumps({
            "intent_type": "chat",
            "confidence": 0.85,
            "action": "explain",
            "target": "topic",
            "parameters": {"query": query},
            "reasoning": "User is asking a general question or seeking explanation",
            "urgency": "casual",
            "specificity": "vague"
        })
    
    def _get_fallback_response(self):
        return json.dumps({
            "intent_type": "chat",
            "confidence": 0.5,
            "action": "respond",
            "target": "user",
            "parameters": {},
            "reasoning": "Could not analyze query properly",
            "urgency": "normal",
            "specificity": "vague"
        })
    
    def _extract_message_content(self, query: str) -> str:
        """Extract implied message content from query"""
        if "running behind" in query or "late" in query:
            return "I'm running behind schedule"
        elif "approved" in query:
            return "The project is approved"
        elif "heads-up" in query:
            return "Heads-up about the current situation"
        else:
            return "Message from me"

async def test_advanced_interpretation():
    print("ðŸ§  Testing Advanced Dynamic AI Interpretation")
    print("=" * 70)
    
    brain = RealisticMockBrain()
    interpreter = AdvancedInterpreter(brain)
    
    test_queries = [
        "Can you give John a heads-up that I'm running behind schedule?",
        "What's it like outside in Tokyo right now?",
        "I need to remember the team sync at 2 PM",
        "Could you show me what's in my documents?",
        "Make the computer ready for bed",
        "How do I fix this issue with my code?",
        "Let Sarah know the project is approved",
        "What's the latest with Tesla stock?",
        "I want to wake up at 7 tomorrow",
        "Can you find that file I was working on yesterday?"
    ]
    
    print("Testing Natural Language Understanding:\n")
    
    for i, query in enumerate(test_queries, 1):
        print(f"{i}. Query: '{query}'")
        
        intent = await interpreter.interpret(query)
        
        print(f"   ðŸŽ¯ Intent: {intent.intent_type.value}")
        print(f"   âš¡ Action: {intent.action}")
        print(f"   ðŸŽ¯ Target: {intent.target}")
        print(f"   ðŸ“Š Confidence: {intent.confidence:.2f}")
        print(f"   ðŸ’­ Reasoning: {intent.reasoning}")
        print()
    
    # Test context awareness
    print("\n" + "=" * 70)
    print("Testing Context Awareness:")
    
    conversation = [
        "What's the weather in London?",
        "What about Paris?",
        "And Tokyo tomorrow?"
    ]
    
    print("\nSimulated conversation:")
    for query in conversation:
        print(f"\nYou: {query}")
        intent = await interpreter.interpret(query)
        print(f"Shadow: [{intent.intent_type.value}] {intent.action} -> {intent.target}")
    
    # Show conversation insights
    insights = interpreter.get_conversation_state()
    print(f"\nðŸ“ˆ Conversation Insights:")
    print(f"   Current topic: {insights['current_topic']}")
    print(f"   Recent actions: {insights['recent_actions']}")
    print(f"   Total interactions: {insights['interaction_count']}")

async def test_smart_nlu():
    print("\n" + "=" * 70)
    print("Testing Smart NLU with Fallbacks:")
    
    brain = RealisticMockBrain()
    smart_nlu = SmartNLU(brain)
    
    # Test some edge cases
    edge_cases = [
        "Weather please",
        "Message the team",
        "Set an alarm",
        "Open something"
    ]
    
    for query in edge_cases:
        print(f"\nQuery: '{query}'")
        intent = await smart_nlu.interpret(query)
        print(f"Result: {intent.intent_type.value} -> {intent.action} (confidence: {intent.confidence:.2f})")

async def main():
    await test_advanced_interpretation()
    await test_smart_nlu()
    
    print("\n" + "=" * 70)
    print("âœ… Advanced Dynamic Interpretation test completed!")
    print("\nðŸŽ¯ Now your AI can:")
    print("  â€¢ Truly understand natural language meaning")
    print("  â€¢ Interpret context and implied actions") 
    print("  â€¢ Handle variations in phrasing")
    print("  â€¢ Maintain conversation context")
    print("  â€¢ Fall back gracefully when uncertain")

if __name__ == "__main__":
    asyncio.run(main())